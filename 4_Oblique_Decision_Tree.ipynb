{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Zadanie: Implementacja Oblique Decision Tree\n","\n","Celem zadania jest stworzenie oblique decision tree do klasyfikacji danych. Oblique decision trees różnią się od tradycyjnych drzew decyzyjnych tym, że używają kombinacji wielu cech do podziału węzłów, co może prowadzić do bardziej precyzyjnych klasyfikacji.\n","\n","### Kroki do wykonania:\n","\n","1. **Zdefiniuj klasę `ObliqueNode`**, która będzie reprezentować węzeł drzewa oblique decision tree.\n","2. **Zaimplementuj funkcję do budowy drzewa** na podstawie zdefiniowanych danych treningowych.\n","3. **Stwórz funkcję `classify`**, która będzie przechodzić przez drzewo i klasyfikować dane na podstawie podanych cech.\n","4. **Przetestuj drzewo na zbiorze danych** (np. Iris dataset).\n","5. **(Opcjonalnie) Dodaj funkcję do wizualizacji drzewa**.\n","\n","### Przykładowy kod startowy:\n","\n","```python\n","import numpy as np\n","from sklearn.datasets import load_iris\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","\n","class ObliqueNode:\n","    def __init__(self, weights=None, threshold=None, left=None, right=None, value=None):\n","        self.weights = weights  # Wagi dla kombinacji cech\n","        self.threshold = threshold  # Wartość progowa dla kombinacji\n","        self.left = left  # Lewe poddrzewo\n","        self.right = right  # Prawe poddrzewo\n","        self.value = value  # Wartość liścia (jeśli jest to liść)\n","\n","def build_oblique_tree(X, y):\n","    # Implementacja budowy drzewa oblique decision tree\n","    # Przykład uproszczony: użycie PCA do redukcji wymiarów jako proxy dla kombinacji cech\n","    from sklearn.decomposition import PCA\n","    pca = PCA(n_components=1)\n","    X_transformed = pca.fit_transform(X)\n","    \n","    # Podział danych na podstawie pierwszej składowej głównej\n","    threshold = np.median(X_transformed)\n","    left_indices = X_transformed <= threshold\n","    right_indices = X_transformed > threshold\n","    \n","    if len(np.unique(y[left_indices])) == 1:\n","        left_node = ObliqueNode(value=np.unique(y[left_indices]))\n","    else:\n","        left_node = build_oblique_tree(X[left_indices], y[left_indices])\n","    \n","    if len(np.unique(y[right_indices])) == 1:\n","        right_node = ObliqueNode(value=np.unique(y[right_indices]))\n","    else:\n","        right_node = build_oblique_tree(X[right_indices], y[right_indices])\n","    \n","    return ObliqueNode(weights=pca.components_, threshold=threshold, left=left_node, right=right_node)\n","\n","def classify(node, sample):\n","    if node.value is not None:\n","        return node.value\n","    \n","    feature_value = np.dot(sample, node.weights)\n","    \n","    if feature_value <= node.threshold:\n","        return classify(node.left, sample)\n","    else:\n","        return classify(node.right, sample)\n","\n","# Załaduj dane Iris\n","iris = load_iris()\n","X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.3, random_state=42)\n","\n","# Budowa drzewa oblique decision tree\n","oblique_tree = build_oblique_tree(X_train, y_train)\n","\n","# Klasyfikacja i ocena modelu\n","predictions = [classify(oblique_tree, sample) for sample in X_test]\n","accuracy = accuracy_score(y_test, predictions)\n","print(f'Accuracy: {accuracy}')\n","```\n","\n","### Wskazówki:\n","\n","1. Zastanów się nad implementacją bardziej zaawansowanych metod podziału węzłów, np. używając optymalizacji do znalezienia najlepszej kombinacji cech.\n","2. Rozważ dodanie parametrów kontrolujących głębokość drzewa lub minimalną liczbę próbek w liściu.\n","3. Pomyśl o implementacji metody przycinania drzewa (pruning) w celu uniknięcia przeuczenia.\n","4. Spróbuj porównać wydajność swojego oblique decision tree z tradycyjnym drzewem decyzyjnym z biblioteki scikit-learn.\n","\n","To zadanie pozwoli na głębsze zrozumienie zaawansowanych koncepcji związanych z drzewami decyzyjnymi oraz pokaże zastosowanie technik takich jak PCA w kontekście tworzenia bardziej złożonych modeli klasyfikacyjnych."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Tutaj możesz zacząć implementację\n","import numpy as np\n","from sklearn.datasets import load_iris\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","\n","# Zdefiniuj klasę ObliqueNode\n","\n","# Zaimplementuj funkcję build_oblique_tree\n","\n","# Zaimplementuj funkcję classify\n","\n","# Załaduj dane i przetestuj swoje drzewo\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Odpowiedź\n","\n","import numpy as np\n","from sklearn.datasets import load_iris\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","from sklearn.decomposition import PCA\n","\n","class ObliqueNode:\n","    def __init__(self, weights=None, threshold=None, left=None, right=None, value=None):\n","        self.weights = weights  # Wagi dla kombinacji cech\n","        self.threshold = threshold  # Wartość progowa dla kombinacji\n","        self.left = left  # Lewe poddrzewo\n","        self.right = right  # Prawe poddrzewo\n","        self.value = value  # Wartość liścia (jeśli jest to liść)\n","\n","def build_oblique_tree(X, y, max_depth=5):\n","    if max_depth == 0 or len(np.unique(y)) == 1:\n","        return ObliqueNode(value=np.argmax(np.bincount(y)))\n","    \n","    pca = PCA(n_components=1)\n","    X_transformed = pca.fit_transform(X)\n","    \n","    threshold = np.median(X_transformed)\n","    left_indices = X_transformed.ravel() <= threshold\n","    right_indices = X_transformed.ravel() > threshold\n","    \n","    if np.all(left_indices) or np.all(right_indices):\n","        return ObliqueNode(value=np.argmax(np.bincount(y)))\n","    \n","    left_node = build_oblique_tree(X[left_indices], y[left_indices], max_depth-1)\n","    right_node = build_oblique_tree(X[right_indices], y[right_indices], max_depth-1)\n","    \n","    return ObliqueNode(weights=pca.components_[0], threshold=threshold, left=left_node, right=right_node)\n","\n","def classify(node, sample):\n","    if node.value is not None:\n","        return node.value\n","    \n","    feature_value = np.dot(sample, node.weights)\n","    \n","    if feature_value <= node.threshold:\n","        return classify(node.left, sample)\n","    else:\n","        return classify(node.right, sample)\n","\n","# Załaduj dane Iris\n","iris = load_iris()\n","X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.3, random_state=42)\n","\n","# Budowa drzewa oblique decision tree\n","oblique_tree = build_oblique_tree(X_train, y_train)\n","\n","# Klasyfikacja i ocena modelu\n","predictions = [classify(oblique_tree, sample) for sample in X_test]\n","accuracy = accuracy_score(y_test, predictions)\n","print(f'Accuracy: {accuracy:.4f}')\n","\n","# Porównanie z tradycyjnym drzewem decyzyjnym\n","from sklearn.tree import DecisionTreeClassifier\n","dt = DecisionTreeClassifier(random_state=42)\n","dt.fit(X_train, y_train)\n","dt_predictions = dt.predict(X_test)\n","dt_accuracy = accuracy_score(y_test, dt_predictions)\n","print(f'Decision Tree Accuracy: {dt_accuracy:.4f}')\n"]}],"metadata":{"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":4}
