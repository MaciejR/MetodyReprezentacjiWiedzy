{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zadania z regresji, rekomendacji i przetwarzania języka naturalnego (NLP)\n",
    "\n",
    "Ten notatnik zawiera praktyczne zadania wykorzystujące rzeczywiste zbiory danych."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Regresja - Przewidywanie cen nieruchomości w Kalifornii\n",
    "\n",
    "**Zbiór danych**: California Housing Dataset\n",
    "\n",
    "**Źródło**: scikit-learn datasets\n",
    "\n",
    "**Opis**: Zbiór zawiera dane o cenach domów w Kalifornii z 1990 roku. Celem jest przewidzenie mediany ceny domu w danym obszarze.\n",
    "\n",
    "**Cechy**:\n",
    "- MedInc (mediana dochodów)\n",
    "- HouseAge (wiek domu)\n",
    "- AveRooms (średnia liczba pokoi)\n",
    "- AveBedrms (średnia liczba sypialni)\n",
    "- Population (populacja)\n",
    "- AveOccup (średnia liczba mieszkańców)\n",
    "- Latitude (szerokość geograficzna)\n",
    "- Longitude (długość geograficzna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import xgboost as xgb\n",
    "\n",
    "def predict_house_prices():\n",
    "    \"\"\"\n",
    "    Przewidywanie cen domów z wykorzystaniem Gradient Boosting i XGBoost\n",
    "    \n",
    "    1. Wczytaj i przygotuj dane\n",
    "    2. Przeprowadź eksploracyjną analizę danych (EDA)\n",
    "    3. Wybierz i przetestuj różne modele regresji\n",
    "    4. Dokonaj optymalizacji hiperparametrów\n",
    "    5. Przeprowadź analizę błędów\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Rekomendacje - System rekomendacji filmów\n",
    "\n",
    "**Zbiór danych**: MovieLens 100K Dataset\n",
    "\n",
    "**Źródło**: GroupLens Research\n",
    "\n",
    "**Opis**: Zbiór zawiera 100,000 ocen od 943 użytkowników dla 1,682 filmów. \n",
    "\n",
    "**Cechy**:\n",
    "- UserID\n",
    "- MovieID\n",
    "- Rating (1-5)\n",
    "- Timestamp\n",
    "- Informacje o filmach (tytuł, gatunek)\n",
    "- Informacje o użytkownikach (wiek, płeć, zawód)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse.linalg import svds\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def build_movie_recommender():\n",
    "    \"\"\"\n",
    "    System rekomendacji filmów wykorzystujący collaborative filtering\n",
    "    \n",
    "    1. Zaimplementuj collaborative filtering (user-based i item-based)\n",
    "    2. Wykorzystaj SVD do redukcji wymiarowości\n",
    "    3. Dodaj content-based filtering używając gatunków filmów\n",
    "    4. Stwórz system hybrydowy\n",
    "    5. Oceń jakość rekomendacji\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. NLP - Analiza sentymentu recenzji produktów\n",
    "\n",
    "**Zbiór danych**: Amazon Product Reviews\n",
    "\n",
    "**Źródło**: Kaggle\n",
    "\n",
    "**Opis**: Zbiór zawiera recenzje produktów z Amazon wraz z oceną gwiazdkową. \n",
    "\n",
    "**Cechy**:\n",
    "- ReviewText\n",
    "- Rating (1-5 gwiazdek)\n",
    "- ProductID\n",
    "- UserID\n",
    "- Summary\n",
    "- Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def analyze_product_sentiment():\n",
    "    \"\"\"\n",
    "    Analiza sentymentu recenzji z wykorzystaniem różnych technik\n",
    "    \n",
    "    1. Preprocesssing tekstu (tokenizacja, usuwanie stop words)\n",
    "    2. Ekstrakcja cech (TF-IDF, word embeddings)\n",
    "    3. Implementacja klasycznego podejścia (RandomForest z TF-IDF)\n",
    "    4. Wykorzystanie modeli transformerowych (BERT)\n",
    "    5. Porównanie wyników różnych podejść\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Regresja - Prognozowanie sprzedaży\n",
    "\n",
    "**Zbiór danych**: Rossmann Store Sales\n",
    "\n",
    "**Źródło**: Kaggle\n",
    "\n",
    "**Opis**: Zbiór zawiera historyczne dane sprzedażowe z sieci sklepów Rossmann. \n",
    "\n",
    "**Cechy**:\n",
    "- Store\n",
    "- DayOfWeek\n",
    "- Date\n",
    "- Sales\n",
    "- Customers\n",
    "- Open\n",
    "- Promo\n",
    "- StateHoliday\n",
    "- SchoolHoliday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def forecast_sales():\n",
    "    \"\"\"\n",
    "    Prognozowanie sprzedaży z wykorzystaniem szeregów czasowych\n",
    "    \n",
    "    1. Przygotowanie cech czasowych (lag features, rolling statistics)\n",
    "    2. Obsługa sezonowości i trendów\n",
    "    3. Implementacja modelu LightGBM\n",
    "    4. Dodanie modelu SARIMA do porównania\n",
    "    5. Analiza ważności cech\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Rekomendacje - System rekomendacji artykułów\n",
    "\n",
    "**Zbiór danych**: Medium Articles Dataset\n",
    "\n",
    "**Źródło**: Kaggle\n",
    "\n",
    "**Opis**: Zbiór zawiera artykuły z Medium wraz z informacjami o interakcjach użytkowników.\n",
    "\n",
    "**Cechy**:\n",
    "- ArticleId\n",
    "- Title\n",
    "- Text\n",
    "- Author\n",
    "- Tags\n",
    "- Claps\n",
    "- Responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "import gensim.models.doc2vec as doc2vec\n",
    "\n",
    "def recommend_articles():\n",
    "    \"\"\"\n",
    "    System rekomendacji artykułów wykorzystujący content-based filtering\n",
    "    \n",
    "    1. Przetwarzanie tekstu i tagów\n",
    "    2. Implementacja TF-IDF dla podobieństwa tekstowego\n",
    "    3. Wykorzystanie Doc2Vec do wektoryzacji artykułów\n",
    "    4. Dodanie popularności jako czynnika rankingowego\n",
    "    5. Ewaluacja rekomendacji\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. NLP - Klasyfikacja tematyczna artykułów\n",
    "\n",
    "**Zbiór danych**: BBC News Dataset\n",
    "\n",
    "**Źródło**: Kaggle\n",
    "\n",
    "**Opis**: Zbiór zawiera artykuły BBC News podzielone na 5 kategorii tematycznych.\n",
    "\n",
    "**Cechy**:\n",
    "- Text (pełny tekst artykułu)\n",
    "- Category (business, entertainment, politics, sport, tech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def classify_news_articles():\n",
    "    \"\"\"\n",
    "    Klasyfikacja tematyczna artykułów\n",
    "    \n",
    "    1. Preprocesssing tekstu\n",
    "    2. Implementacja klasycznego podejścia (BoW + klasyfikator)\n",
    "    3. Wykorzystanie BERT do klasyfikacji\n",
    "    4. Analiza błędnie sklasyfikowanych przypadków\n",
    "    5. Wizualizacja wyników (confusion matrix, raporty)\n",
    "    \"\"\"\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
