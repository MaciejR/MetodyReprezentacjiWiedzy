{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zadania z klasyfikacji, detekcji anomalii i segmentacji\n",
    "\n",
    "Ten notatnik zawiera praktyczne zadania wykorzystujące rzeczywiste zbiory danych."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Klasyfikacja - Diagnoza cukrzycy\n",
    "\n",
    "**Zbiór danych**: Pima Indians Diabetes Database\n",
    "\n",
    "**Źródło**: UCI Machine Learning Repository\n",
    "\n",
    "**Opis**: Zbiór zawiera dane medyczne pacjentek pochodzących z plemienia Pima Indians. Celem jest przewidzenie czy pacjentka choruje na cukrzycę.\n",
    "\n",
    "**Cechy**:\n",
    "- Liczba ciąż\n",
    "- Stężenie glukozy we krwi\n",
    "- Ciśnienie krwi\n",
    "- Grubość fałdu skórnego\n",
    "- Poziom insuliny\n",
    "- BMI\n",
    "- Funkcja rodowodu cukrzycy\n",
    "- Wiek"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pima Indians Diabetes Database:\n",
    "\n",
    "\n",
    "https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\n",
    "Alternatywnie na UCI: https://archive.ics.uci.edu/dataset/267/diabetes\n",
    "\n",
    "\n",
    "Credit Card Fraud Detection:\n",
    "\n",
    "\n",
    "https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud\n",
    "Oryginalny zbiór na Kaggle zawiera 284,807 transakcji\n",
    "\n",
    "\n",
    "Mall Customer Segmentation Data:\n",
    "\n",
    "\n",
    "https://www.kaggle.com/datasets/vjchoudhary7/customer-segmentation-tutorial-in-python\n",
    "Alternatywnie dostępny na: https://www.kaggle.com/shwetabh123/mall-customers\n",
    "\n",
    "\n",
    "Bank Customer Churn:\n",
    "\n",
    "\n",
    "https://www.kaggle.com/datasets/adammaus/predicting-churn-for-bank-customers\n",
    "Alternatywnie: https://www.kaggle.com/datasets/shrutimechlearn/churn-modelling\n",
    "\n",
    "\n",
    "Manufacturing Process Failures:\n",
    "\n",
    "\n",
    "https://archive.ics.uci.edu/dataset/601/ai4i+2020+predictive+maintenance+dataset\n",
    "Jest to zbiór AI4I 2020 Predictive Maintenance Dataset\n",
    "\n",
    "\n",
    "Online Retail Dataset:\n",
    "\n",
    "\n",
    "https://archive.ics.uci.edu/dataset/352/online+retail\n",
    "Alternatywnie dostępny na Kaggle: https://www.kaggle.com/datasets/carrie1/ecommerce-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Wczytaj dane\n",
    "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
    "column_names = ['pregnancies', 'glucose', 'blood_pressure', 'skin_thickness', 'insulin',\n",
    "                'bmi', 'diabetes_pedigree', 'age', 'outcome']\n",
    "df = pd.read_csv(url, names=column_names)\n",
    "\n",
    "# Zadanie: Zaimplementuj model klasyfikacji\n",
    "def train_diabetes_classifier(X, y):\n",
    "    # Twoje rozwiązanie\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Detekcja anomalii - Wykrywanie oszustw kartami kredytowymi\n",
    "\n",
    "**Zbiór danych**: Credit Card Fraud Detection\n",
    "\n",
    "**Źródło**: Kaggle\n",
    "\n",
    "**Opis**: Zbiór zawiera transakcje kartami kredytowymi, z których część to oszustwa. Celem jest wykrycie podejrzanych transakcji.\n",
    "\n",
    "**Cechy**:\n",
    "- 28 przekształconych cech (V1-V28) ze względu na poufność\n",
    "- Time - czas od pierwszej transakcji\n",
    "- Amount - kwota transakcji\n",
    "- Class - zmienna określająca czy transakcja jest oszustwem (1) czy nie (0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "def detect_credit_card_fraud(transactions):\n",
    "    \"\"\"\n",
    "    Wykrywanie oszustw z wykorzystaniem Isolation Forest i Local Outlier Factor\n",
    "    \n",
    "    1. Przeskaluj cechy używając RobustScaler\n",
    "    2. Zaimplementuj Isolation Forest\n",
    "    3. Dodaj Local Outlier Factor jako drugi model\n",
    "    4. Połącz wyniki z obu modeli\n",
    "    \"\"\"\n",
    "    # Twoje rozwiązanie\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Segmentacja - Segmentacja klientów sklepu\n",
    "\n",
    "**Zbiór danych**: Mall Customer Segmentation Data\n",
    "\n",
    "**Źródło**: Kaggle\n",
    "\n",
    "**Opis**: Zbiór zawiera dane klientów centrum handlowego. Celem jest podzielenie klientów na grupy o podobnych zachowaniach zakupowych.\n",
    "\n",
    "**Cechy**:\n",
    "- CustomerID\n",
    "- Gender\n",
    "- Age\n",
    "- Annual Income (k$)\n",
    "- Spending Score (1-100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "def segment_mall_customers(customer_data):\n",
    "    \"\"\"\n",
    "    Segmentacja klientów z wykorzystaniem K-means\n",
    "    \n",
    "    1. Przygotuj dane (standaryzacja)\n",
    "    2. Znajdź optymalną liczbę klastrów używając metody łokcia i współczynnika silhouette\n",
    "    3. Przeprowadź klasteryzację\n",
    "    4. Przeanalizuj charakterystykę każdego segmentu\n",
    "    \"\"\"\n",
    "    # Twoje rozwiązanie\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Klasyfikacja - Przewidywanie rezygnacji klientów banku\n",
    "\n",
    "**Zbiór danych**: Bank Customer Churn\n",
    "\n",
    "**Źródło**: Kaggle\n",
    "\n",
    "**Opis**: Zbiór zawiera dane klientów banku. Celem jest przewidzenie, którzy klienci zrezygnują z usług banku.\n",
    "\n",
    "**Cechy**:\n",
    "- CreditScore\n",
    "- Geography\n",
    "- Gender\n",
    "- Age\n",
    "- Tenure\n",
    "- Balance\n",
    "- NumOfProducts\n",
    "- HasCrCard\n",
    "- IsActiveMember\n",
    "- EstimatedSalary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def predict_bank_churn(customer_data):\n",
    "    \"\"\"\n",
    "    Przewidywanie rezygnacji klientów\n",
    "    \n",
    "    1. Przygotuj dane (kodowanie zmiennych kategorycznych, standaryzacja)\n",
    "    2. Wybierz istotne cechy\n",
    "    3. Zbuduj model Gradient Boosting\n",
    "    4. Przeprowadź walidację krzyżową\n",
    "    5. Przeanalizuj ważność cech\n",
    "    \"\"\"\n",
    "    # Twoje rozwiązanie\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Detekcja anomalii - Wykrywanie wadliwych produktów\n",
    "\n",
    "**Zbiór danych**: Manufacturing Process Failures\n",
    "\n",
    "**Źródło**: UCI Machine Learning Repository\n",
    "\n",
    "**Opis**: Zbiór zawiera pomiary z procesu produkcyjnego. Celem jest wykrycie wadliwych produktów.\n",
    "\n",
    "**Cechy**:\n",
    "- Temperatura procesu\n",
    "- Ciśnienie\n",
    "- Wilgotność\n",
    "- Wibracje\n",
    "- Inne parametry procesu produkcyjnego"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.svm import OneClassSVM\n",
    "\n",
    "def detect_manufacturing_anomalies(process_data):\n",
    "    \"\"\"\n",
    "    Wykrywanie wadliwych produktów\n",
    "    \n",
    "    1. Przygotuj dane (usunięcie odstających wartości, normalizacja)\n",
    "    2. Zastosuj Elliptic Envelope do wykrycia anomalii\n",
    "    3. Porównaj wyniki z One-Class SVM\n",
    "    4. Określ progi dla różnych poziomów pewności\n",
    "    \"\"\"\n",
    "    # Twoje rozwiązanie\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Segmentacja - Grupowanie produktów\n",
    "\n",
    "**Zbiór danych**: Online Retail Dataset\n",
    "\n",
    "**Źródło**: UCI Machine Learning Repository\n",
    "\n",
    "**Opis**: Zbiór zawiera transakcje sprzedaży online. Celem jest pogrupowanie produktów na podstawie wzorców zakupowych.\n",
    "\n",
    "**Cechy**:\n",
    "- InvoiceNo\n",
    "- StockCode\n",
    "- Description\n",
    "- Quantity\n",
    "- InvoiceDate\n",
    "- UnitPrice\n",
    "- CustomerID\n",
    "- Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def segment_products(sales_data):\n",
    "    \"\"\"\n",
    "    Segmentacja produktów\n",
    "    \n",
    "    1. Przygotuj cechy (częstość zakupów, średnia wartość koszyka, sezonowość)\n",
    "    2. Zredukuj wymiarowość używając PCA\n",
    "    3. Zastosuj DBSCAN do znalezienia klastrów\n",
    "    4. Przeanalizuj charakterystykę każdego segmentu\n",
    "    \"\"\"\n",
    "    # Twoje rozwiązanie\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
