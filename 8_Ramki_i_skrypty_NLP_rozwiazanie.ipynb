{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rozwiązania zadań z analizy ramek semantycznych i skryptów\n",
    "\n",
    "W tym notebooku przedstawimy rozwiązania zadań dotyczących analizy tekstu z wykorzystaniem ramek semantycznych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import framenet as fn\n",
    "import spacy\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "# Pobieranie potrzebnych zasobów\n",
    "nltk.download('framenet_v17')\n",
    "\n",
    "# Wczytanie modeli spaCy\n",
    "nlp_sm = spacy.load(\"en_core_web_sm\")\n",
    "nlp_lg = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Identyfikacja ról semantycznych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_semantic_roles(sentence):\n",
    "    doc = nlp_sm(sentence)\n",
    "    roles = defaultdict(list)\n",
    "    \n",
    "    for token in doc:\n",
    "        if token.dep_ in ['nsubj', 'dobj', 'iobj']:\n",
    "            # Mapowanie zależności składniowych na role semantyczne\n",
    "            if token.dep_ == 'nsubj':\n",
    "                role = 'Agent'\n",
    "            elif token.dep_ == 'dobj':\n",
    "                role = 'Patient'\n",
    "            else:\n",
    "                role = 'Recipient'\n",
    "                \n",
    "            roles[token.head.text].append((token.text, role))\n",
    "            \n",
    "    return dict(roles)\n",
    "\n",
    "# Przykład użycia\n",
    "sentence = \"The chef cooked a delicious meal for his guests.\"\n",
    "semantic_roles = identify_semantic_roles(sentence)\n",
    "print(\"Role semantyczne:\")\n",
    "for verb, args in semantic_roles.items():\n",
    "    print(f\"\\nCzasownik: {verb}\")\n",
    "    for arg, role in args:\n",
    "        print(f\"- {arg}: {role}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Wizualizacja ramek semantycznych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_semantic_frames(frames):\n",
    "    G = nx.DiGraph()\n",
    "    \n",
    "    for verb, frame in frames:\n",
    "        # Dodanie węzła czasownika\n",
    "        G.add_node(verb, node_type='verb')\n",
    "        # Dodanie węzła ramki\n",
    "        G.add_node(frame, node_type='frame')\n",
    "        # Dodanie krawędzi\n",
    "        G.add_edge(verb, frame)\n",
    "        \n",
    "        # Dodanie elementów ramki\n",
    "        frame_info = fn.frame(frame)\n",
    "        for fe in frame_info.FE.values():\n",
    "            if fe.coreType == 'Core':\n",
    "                G.add_node(fe.name, node_type='element')\n",
    "                G.add_edge(frame, fe.name)\n",
    "    \n",
    "    # Rysowanie grafu\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    pos = nx.spring_layout(G)\n",
    "    \n",
    "    # Rysowanie węzłów różnych typów\n",
    "    nx.draw_networkx_nodes(G, pos, \n",
    "                          node_color='lightblue',\n",
    "                          node_size=2000,\n",
    "                          nodelist=[n for n,d in G.nodes(data=True) if d['node_type']=='verb'])\n",
    "    nx.draw_networkx_nodes(G, pos,\n",
    "                          node_color='lightgreen',\n",
    "                          node_size=1500,\n",
    "                          nodelist=[n for n,d in G.nodes(data=True) if d['node_type']=='frame'])\n",
    "    nx.draw_networkx_nodes(G, pos,\n",
    "                          node_color='lightpink',\n",
    "                          node_size=1000,\n",
    "                          nodelist=[n for n,d in G.nodes(data=True) if d['node_type']=='element'])\n",
    "    \n",
    "    nx.draw_networkx_edges(G, pos)\n",
    "    nx.draw_networkx_labels(G, pos)\n",
    "    \n",
    "    plt.title(\"Wizualizacja ramek semantycznych\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Przykład użycia\n",
    "identified_frames = identify_semantic_frames(sentence)\n",
    "visualize_semantic_frames(identified_frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Analiza dłuższego tekstu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "longer_text = \"\"\"\n",
    "The skilled chef carefully prepared a magnificent feast in the restaurant's kitchen. \n",
    "He chopped fresh vegetables and seasoned the meat with exotic spices. \n",
    "The sous chef assisted him while the waiters arranged the dining room. \n",
    "Finally, they served the delicious dishes to the eager guests.\n",
    "\"\"\"\n",
    "\n",
    "def analyze_text(text):\n",
    "    sentences = [sent.text.strip() for sent in nlp_sm(text).sents]\n",
    "    results = []\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        frames = identify_semantic_frames(sentence)\n",
    "        roles = identify_semantic_roles(sentence)\n",
    "        results.append({\n",
    "            'sentence': sentence,\n",
    "            'frames': frames,\n",
    "            'roles': roles\n",
    "        })\n",
    "    \n",
    "    return results\n",
    "\n",
    "analysis_results = analyze_text(longer_text)\n",
    "for result in analysis_results:\n",
    "    print(f\"\\nZdanie: {result['sentence']}\")\n",
    "    print(\"Ramki:\")\n",
    "    for verb, frame in result['frames']:\n",
    "        print(f\"- {verb}: {frame}\")\n",
    "    print(\"Role:\")\n",
    "    for verb, roles in result['roles'].items():\n",
    "        print(f\"- {verb}: {roles}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Analiza różnych typów zdań"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "different_sentences = {\n",
    "    'oznajmujące': \"The chef prepares the meal.\",\n",
    "    'pytające': \"What is the chef preparing?\",\n",
    "    'rozkazujące': \"Prepare the meal quickly!\",\n",
    "    'wykrzyknikowe': \"How wonderfully the chef cooks!\"\n",
    "}\n",
    "\n",
    "for sent_type, sent in different_sentences.items():\n",
    "    print(f\"\\nTyp zdania: {sent_type}\")\n",
    "    print(f\"Zdanie: {sent}\")\n",
    "    \n",
    "    frames = identify_semantic_frames(sent)\n",
    "    roles = identify_semantic_roles(sent)\n",
    "    \n",
    "    print(\"Ramki:\")\n",
    "    for verb, frame in frames:\n",
    "        print(f\"- {verb}: {frame}\")\n",
    "    print(\"Role:\")\n",
    "    for verb, role_list in roles.items():\n",
    "        print(f\"- {verb}: {role_list}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Porównanie modeli spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_spacy_models(sentence):\n",
    "    print(f\"Zdanie: {sentence}\\n\")\n",
    "    \n",
    "    # Analiza z użyciem modelu small\n",
    "    doc_sm = nlp_sm(sentence)\n",
    "    print(\"Model en_core_web_sm:\")\n",
    "    for token in doc_sm:\n",
    "        print(f\"Token: {token.text}, POS: {token.pos_}, DEP: {token.dep_}\")\n",
    "    \n",
    "    print(\"\\nModel en_core_web_lg:\")\n",
    "    # Analiza z użyciem modelu large\n",
    "    doc_lg = nlp_lg(sentence)\n",
    "    for token in doc_lg:\n",
    "        print(f\"Token: {token.text}, POS: {token.pos_}, DEP: {token.dep_}\")\n",
    "\n",
    "test_sentence = \"The experienced chef masterfully prepared the complex dish.\"\n",
    "compare_spacy_models(test_sentence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}